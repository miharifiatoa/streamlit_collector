import re
import json
from typing import List, Dict, Tuple
from collections import defaultdict
from tqdm import tqdm
import streamlit as st

def extract_sentences(text: str, word: str) -> List[str]:
    """
    Extrait les phrases contenant un mot sp√©cifique.
    
    Args:
        text (str): Texte source
        word (str): Mot √† rechercher
        
    Returns:
        List[str]: Liste des phrases contenant le mot
    """
    sentences = re.split(r'(?<=[.!?])\s+', text)
    return [s.strip() for s in sentences if word.lower() in s.lower()]

def get_word_context(text: str, word: str, window: int = 5) -> str:
    """
    Extrait le contexte autour d'un mot avec une fen√™tre donn√©e.
    
    Args:
        text (str): Texte source
        word (str): Mot √† rechercher
        window (int): Nombre de mots avant/apr√®s
        
    Returns:
        str: Contexte du mot
    """
    words = text.lower().split()
    try:
        idx = words.index(word.lower())
        start = max(0, idx - window)
        end = min(len(words), idx + window + 1)
        return " ".join(words[start:end])
    except ValueError:
        return ""

def find_best_example(text: str, word: str) -> str:
    """
    Trouve le meilleur exemple d'utilisation d'un mot.
    
    Pour le premier extrait de phrase qui respecte les r√®gles suivantes:
    - La phrase doit se terminer par un caract√®re de ponctuation (".", "!", ou "?").
    - La phrase est convertie en minuscules et nettoy√©e (suppression des chiffres et caract√®res sp√©ciaux).
    - Extrait 5 mots avant et 5 mots apr√®s le mot cherch√© (s'il existe).
    
    Args:
        text (str): Texte source
        word (str): Mot √† rechercher
        
    Returns:
        str: Contexte extrait si la phrase est valide, sinon une cha√Æne vide.
    """
    # S√©paration en phrases en se basant sur la ponctuation
    sentences = re.split(r'(?<=[.!?])\s+', text)
    for sentence in sentences:
        # V√©rifier que c'est bien une phrase (se termine par ponctuation)
        if not sentence.strip().endswith(('.', '!', '?')):
            continue
        if word.lower() in sentence.lower():
            # Conversion en minuscules et nettoyage de la phrase:
            cleaned_sentence = sentence.lower()
            # Suppression des chiffres et caract√®res sp√©ciaux (conserve uniquement les lettres et les espaces)
            cleaned_sentence = re.sub(r'[^a-z\s]', '', cleaned_sentence)
            word_list = cleaned_sentence.split()
            try:
                idx = word_list.index(word.lower())
                start = max(0, idx - 5)
                end = idx + 6  # 5 mots apr√®s le mot (le mot lui-m√™me est inclus)
                context = " ".join(word_list[start:end])
                return context
            except ValueError:
                continue
    return ""

def clean_text(text: str) -> str:
    """
    Nettoie le texte en supprimant tous les caract√®res sp√©ciaux.
    
    Le texte est converti en minuscules et ne conserve que lettres, chiffres, espaces ainsi que la ponctuation essentielle.
    
    Args:
        text (str): Texte √† nettoyer
        
    Returns:
        str: Texte nettoy√©
    """
    # Conversion en minuscules
    text = text.lower()
    # Suppression de tous les caract√®res sp√©ciaux (on conserve les lettres, chiffres, espaces et ponctuation simple)
    text = re.sub(r'[^a-z0-9\s.!?]', '', text)
    # Normalisation des espaces
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def process_text(text: str, progress_bar=None) -> Dict[str, List[str]]:
    """
    Traite le texte pour extraire les mots uniques et cr√©e un format JSON.
    
    Supprime les mots compos√©s d'une seule lettre.
    
    Args:
        text (str): Texte brut √† traiter
        progress_bar: Barre de progression Streamlit (optionnel)
        
    Returns:
        Dict[str, List[str]]: Dictionnaire format√© avec input/output/examples
    """
    # Nettoyage initial du texte (conversion en minuscules et nettoyage simple)
    clean_text_content = clean_text(text)
    
    # Extraction des mots uniques et suppression des mots d'une seule lettre
    words = [word for word in re.findall(r'\b\w+\b', clean_text_content) if word.isalpha() and len(word) > 1]
    unique_words = list(dict.fromkeys(words))
    
    # Cr√©ation des exemples pour chaque mot
    examples = []
    total = len(unique_words)
    
    if progress_bar:
        progress_text = "Traitement des mots en cours..."
        progress_bar.write(progress_text)
        progress = progress_bar.progress(0)
        for i, word in enumerate(unique_words):
            example = find_best_example(text, word)
            examples.append(example)
            progress.progress((i + 1) / total)
            progress_text = f"Traitement: {i+1}/{total} mots"
            progress_bar.write(progress_text)
    else:
        for word in tqdm(unique_words, desc="Extraction des exemples"):
            example = find_best_example(text, word)
            examples.append(example)
    
    result = {
        "input": unique_words,
        "output": [""] * len(unique_words),
        "examples": examples
    }
    
    return result

def save_to_json(data: Dict, output_file: str):
    """Sauvegarde les donn√©es dans un fichier JSON."""
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# Version console
if __name__ == "__main__":
    try:
        with open('data/clean/datasets.txt', 'r', encoding='utf-8') as f:
            text = f.read()
        print("üîÑ D√©but du traitement...")
        result = process_text(text)
        print("üíæ Sauvegarde des r√©sultats...")
        save_to_json(result, 'data/processed/output.json')
        print("‚úÖ Traitement termin√© avec succ√®s!")
        print(f"üìä Statistiques:")
        print(f"- Mots uniques: {len(result['input'])}")
        print(f"- Exemples trouv√©s: {len([x for x in result['examples'] if x])}")
    except Exception as e:
        print(f"‚ùå Erreur lors du traitement: {str(e)}")